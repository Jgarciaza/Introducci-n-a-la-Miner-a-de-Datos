{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introducción:\n",
        "En la etapa de preprocesamiento se tiene como objetivo abordar técnicas que permitan\n",
        "obtener información organizada, evitar información que pueda ser redundante, identificar\n",
        "posibles problemas presentes en las bases de datos y hacer el respectivo tratamiento.\n",
        "Específicamente, en este trabajo se desarrollarán metodologías para el tratamiento de datos\n",
        "atípicos y datos faltantes.\n",
        "\n",
        "1. A partir del dataset ruidoso.txt realice los siguientes análisis:\n",
        "- **a.** Cargue y explore el dataset explicando en qué consiste y las características que\n",
        "posee el mismo."
      ],
      "metadata": {
        "id": "ZpeexT8Qr-sa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2XDjBwSr2Jd"
      },
      "outputs": [],
      "source": [
        "# Importar librerías\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt #librería usada para graficar\n",
        "import seaborn as sns #Librería usada para visualización"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lectura\n",
        "ruta='/content/drive/Othercomputers/Mi portátil/SEMESTRE 9/Introduccion mineria de datos/Parcial/ruidoso.txt'\n",
        "data=pd.read_csv(ruta)\n",
        "data"
      ],
      "metadata": {
        "id": "myHI8i3zsDjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cuanto registros hay?"
      ],
      "metadata": {
        "id": "7Oo5AVQosJwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dat_info =data.info()\n",
        "data_size=data.size\n",
        "dat_info, data_size"
      ],
      "metadata": {
        "id": "CAJFBQ-SsH6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datos faltantes(NaN´s)"
      ],
      "metadata": {
        "id": "3IPSudsFsME-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().sum()"
      ],
      "metadata": {
        "id": "HjHfHy1csOpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tipo de datos"
      ],
      "metadata": {
        "id": "W4YL6RkjsRGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes\n",
        "\n"
      ],
      "metadata": {
        "id": "uZrePcabsSdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eliminacion de variable"
      ],
      "metadata": {
        "id": "d-1chTAQsVLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(columns=[\"Unnamed: 0\"])"
      ],
      "metadata": {
        "id": "oYRlhjAJsW2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analisis inicial"
      ],
      "metadata": {
        "id": "eds9ulaxsaLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.float_format', '{:.2f}'.format)\n",
        "# Mostrar las primeras filas para confirmar la carga correcta y obtener estadísticas descriptivas básicas de los datos.\n",
        "data_head = data.head()\n",
        "data_description = data.describe()\n",
        "\n",
        "data_head, data_description"
      ],
      "metadata": {
        "id": "KIVG_HENsb23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# b) Realice un breve análisis exploratorio para identificar la distribución de las variables usadas en la base de datos ¿será que existe relación entre las variables?"
      ],
      "metadata": {
        "id": "NNXBl4Eusphg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distribución de las variables"
      ],
      "metadata": {
        "id": "u-ewOwetsj6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "3q5TeinassQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración de estilos de gráficos\n",
        "sns.set(style=\"whitegrid\")"
      ],
      "metadata": {
        "id": "aey5uFCossN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear subgráficos\n",
        "fig, axes = plt.subplots(2,2, figsize=(12, 8))\n",
        "fig.suptitle('Distribución de Variables')\n",
        "sns.histplot(data['Road_55dB'], bins=20, kde=True, ax=axes[0, 0])\n",
        "axes[0, 0].set_title('Distribución de Road_55dB')\n",
        "\n",
        "sns.histplot(data['Road_60dB'], bins=20, kde=True, ax=axes[0, 1])\n",
        "axes[0, 1].set_title('Distribución de Road_60dB')\n",
        "\n",
        "sns.histplot(data['Railways_65dB'], bins=20, kde=True, ax=axes[1, 0])\n",
        "axes[1, 0].set_title('Distribución de Railways_65dB')\n",
        "\n",
        "sns.histplot(data['Industry_65dB'], bins=20, kde=True, ax=axes[1, 1])\n",
        "axes[1, 1].set_title('Distribución de Industry_65dB')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])"
      ],
      "metadata": {
        "id": "isFaIfkGssLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.ticker import ScalarFormatter\n",
        "\n",
        "# Crear subgráficos en una sola columna vertical\n",
        "fig, axes = plt.subplots(4, 1, figsize=(6, 16))\n",
        "fig.suptitle('Distribución de Variables')\n",
        "\n",
        "# Configurar ScalarFormatter para usar números enteros en lugar de notación científica\n",
        "formatter = ScalarFormatter(useOffset=False)\n",
        "formatter.set_scientific(False)\n",
        "\n",
        "# Distribución de Road_55dB\n",
        "sns.histplot(data['Road_55dB'], bins=20, kde=True, ax=axes[0], orientation='vertical')\n",
        "axes[0].set_title('Distribución de Road_55dB')\n",
        "axes[0].xaxis.set_major_formatter(formatter)\n",
        "axes[0].tick_params(axis='x', rotation=90)\n",
        "\n",
        "# Distribución de Road_60dB\n",
        "sns.histplot(data['Road_60dB'], bins=20, kde=True, ax=axes[1], orientation='vertical')\n",
        "axes[1].set_title('Distribución de Road_60dB')\n",
        "axes[1].xaxis.set_major_formatter(formatter)\n",
        "axes[1].tick_params(axis='x', rotation=90)\n",
        "\n",
        "# Distribución de Railways_65dB\n",
        "sns.histplot(data['Railways_65dB'], bins=20, kde=True, ax=axes[2], orientation='vertical')\n",
        "axes[2].set_title('Distribución de Railways_65dB')\n",
        "axes[2].xaxis.set_major_formatter(formatter)\n",
        "axes[2].tick_params(axis='x', rotation=90)\n",
        "\n",
        "# Distribución de Industry_65dB\n",
        "sns.histplot(data['Industry_65dB'], bins=20, kde=True, ax=axes[3], orientation='vertical')\n",
        "axes[3].set_title('Distribución de Industry_65dB')\n",
        "axes[3].xaxis.set_major_formatter(formatter)\n",
        "axes[3].tick_params(axis='x', rotation=90)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xEYudA7zssFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Caso variable \"Industry_65dB:\""
      ],
      "metadata": {
        "id": "LZvG4YFos5yK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Caso 1: Eliminacion:"
      ],
      "metadata": {
        "id": "mt2ohum_s890"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1= data\n",
        "data1= data1.dropna()"
      ],
      "metadata": {
        "id": "xy3I0gF4s_Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1.describe()"
      ],
      "metadata": {
        "id": "liDqad-3tA5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1.isna().sum()"
      ],
      "metadata": {
        "id": "GkxpW03rtCAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.ticker import ScalarFormatter\n",
        "\n",
        "# Crear subgráficos en una sola columna vertical\n",
        "fig, axes = plt.subplots(4, 1, figsize=(6, 16))\n",
        "fig.suptitle('Distribución de Variables')\n",
        "\n",
        "# Configurar ScalarFormatter para usar números enteros en lugar de notación científica\n",
        "formatter = ScalarFormatter(useOffset=False)\n",
        "formatter.set_scientific(False)\n",
        "\n",
        "# Distribución de Road_55dB\n",
        "sns.histplot(data1['Road_55dB'], bins=20, kde=True, ax=axes[0], orientation='vertical')\n",
        "axes[0].set_title('Distribución de Road_55dB')\n",
        "axes[0].xaxis.set_major_formatter(formatter)\n",
        "axes[0].tick_params(axis='x', rotation=90)\n",
        "\n",
        "# Distribución de Road_60dB\n",
        "sns.histplot(data1['Road_60dB'], bins=20, kde=True, ax=axes[1], orientation='vertical')\n",
        "axes[1].set_title('Distribución de Road_60dB')\n",
        "axes[1].xaxis.set_major_formatter(formatter)\n",
        "axes[1].tick_params(axis='x', rotation=90)\n",
        "\n",
        "# Distribución de Railways_65dB\n",
        "sns.histplot(data1['Railways_65dB'], bins=20, kde=True, ax=axes[2], orientation='vertical')\n",
        "axes[2].set_title('Distribución de Railways_65dB')\n",
        "axes[2].xaxis.set_major_formatter(formatter)\n",
        "axes[2].tick_params(axis='x', rotation=90)\n",
        "\n",
        "# Distribución de Industry_65dB\n",
        "sns.histplot(data1['Industry_65dB'], bins=20, kde=True, ax=axes[3], orientation='vertical')\n",
        "axes[3].set_title('Distribución de Industry_65dB')\n",
        "axes[3].xaxis.set_major_formatter(formatter)\n",
        "axes[3].tick_params(axis='x', rotation=90)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ACWiUSndtD_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Diagramas de Dispersión"
      ],
      "metadata": {
        "id": "TbKVhWRatME2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Crear el diagrama de dispersión\n",
        "sns.scatterplot(x='Road_55dB', y='Road_60dB', data=data1)\n",
        "plt.title('Diagrama de dispersión de Road_55dB vs Road_60dB')\n",
        "plt.xlabel('Road_55dB')\n",
        "plt.ylabel('Road_60dB')\n",
        "\n",
        "# Configurar ScalarFormatter para evitar la notación científica\n",
        "formatter = ScalarFormatter(useOffset=False)\n",
        "formatter.set_scientific(False)\n",
        "\n",
        "# Aplicar el formatter a los ejes\n",
        "ax = plt.gca()\n",
        "ax.xaxis.set_major_formatter(formatter)\n",
        "ax.yaxis.set_major_formatter(formatter)\n",
        "# Rotar las etiquetas del eje x para que aparezcan verticalmente\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "3UU8aXnstLfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sns.scatterplot(x='Road_55dB', y='Railways_65dB', data=data1)\n",
        "plt.title('Diagrama de dispersión de Road_55dB vs Railways_65dB')\n",
        "plt.xlabel('Road_55dB')\n",
        "plt.ylabel('Railways_65dB')\n",
        "\n",
        "# Configurar ScalarFormatter para evitar la notación científica\n",
        "formatter = ScalarFormatter(useOffset=False)\n",
        "formatter.set_scientific(False)\n",
        "\n",
        "# Aplicar el formatter a los ejes\n",
        "ax = plt.gca()\n",
        "ax.xaxis.set_major_formatter(formatter)\n",
        "ax.yaxis.set_major_formatter(formatter)\n",
        "# Rotar las etiquetas del eje x para que aparezcan verticalmente\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EcO6mWBRtJU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sns.scatterplot(x='Road_60dB', y='Railways_65dB', data=data1)\n",
        "plt.title('Diagrama de dispersión de Road_60dB vs Railways_65dB')\n",
        "plt.ylabel('Railways_65dB')\n",
        "plt.ylabel('Road_60dB')\n",
        "\n",
        "# Configurar ScalarFormatter para evitar la notación científica\n",
        "formatter = ScalarFormatter(useOffset=False)\n",
        "formatter.set_scientific(False)\n",
        "\n",
        "# Aplicar el formatter a los ejes\n",
        "ax = plt.gca()\n",
        "ax.xaxis.set_major_formatter(formatter)\n",
        "ax.yaxis.set_major_formatter(formatter)\n",
        "# Rotar las etiquetas del eje x para que aparezcan verticalmente\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XUOn6R2TtP36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sns.scatterplot(x='Road_55dB', y='Industry_65dB', data=data1)\n",
        "plt.title('Diagrama de dispersión de Road_55dB vs Industry_65dB')\n",
        "plt.xlabel('Road_55dB')\n",
        "plt.ylabel('Industry_65dB')\n",
        "\n",
        "# Configurar ScalarFormatter para evitar la notación científica\n",
        "formatter = ScalarFormatter(useOffset=False)\n",
        "formatter.set_scientific(False)\n",
        "\n",
        "# Aplicar el formatter a los ejes\n",
        "ax = plt.gca()\n",
        "ax.xaxis.set_major_formatter(formatter)\n",
        "ax.yaxis.set_major_formatter(formatter)\n",
        "# Rotar las etiquetas del eje x para que aparezcan verticalmente\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oAuFguHotRdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x='Road_60dB', y='Industry_65dB', data=data1)\n",
        "plt.title('Diagrama de dispersión de Road_60dB vs Industry_65dB')\n",
        "plt.xlabel('Road_60dB')\n",
        "plt.ylabel('Industry_65dB')\n",
        "\n",
        "# Configurar ScalarFormatter para evitar la notación científica\n",
        "formatter = ScalarFormatter(useOffset=False)\n",
        "formatter.set_scientific(False)\n",
        "\n",
        "# Aplicar el formatter a los ejes\n",
        "ax = plt.gca()\n",
        "ax.xaxis.set_major_formatter(formatter)\n",
        "ax.yaxis.set_major_formatter(formatter)\n",
        "# Rotar las etiquetas del eje x para que aparezcan verticalmente\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7l13SRNctUzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sns.scatterplot(x='Railways_65dB', y='Industry_65dB', data=data1)\n",
        "plt.title('Diagrama de dispersión de Railways_65dB vs Industry_65dB')\n",
        "plt.xlabel('Railways_65dB')\n",
        "plt.ylabel('Industry_65dB')\n",
        "\n",
        "# Configurar ScalarFormatter para evitar la notación científica\n",
        "formatter = ScalarFormatter(useOffset=False)\n",
        "formatter.set_scientific(False)\n",
        "\n",
        "# Aplicar el formatter a los ejes\n",
        "ax = plt.gca()\n",
        "ax.xaxis.set_major_formatter(formatter)\n",
        "ax.yaxis.set_major_formatter(formatter)\n",
        "# Rotar las etiquetas del eje x para que aparezcan verticalmente\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yGrOwoggtWv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlación de pearson"
      ],
      "metadata": {
        "id": "Eels4GQQtY4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zWpX1LoptYyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculando la matriz de correlación\n",
        "correlation_matrix = data1.corr()\n",
        "\n",
        "# Generando un mapa de calor para visualizar las correlaciones\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.title('Mapa de Calor de la Correlación entre Variables')\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VEcUChzVtWtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verifique si existen problemas de datos atípicos en cada una de las variables usando las metodologías de detección a nivel univariado."
      ],
      "metadata": {
        "id": "4iCDkZtTtgQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Boxplot(diagrama de cajas)"
      ],
      "metadata": {
        "id": "lGSQSTEuti-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.ticker import ScalarFormatter\n",
        "\n",
        "# Crear subgráficos en una sola columna vertical\n",
        "fig, axes = plt.subplots(4, 1, figsize=(6, 16))\n",
        "fig.suptitle('Boxplot de Variables')\n",
        "\n",
        "# Configurar ScalarFormatter para usar números enteros en lugar de notación científica\n",
        "formatter = ScalarFormatter(useOffset=False)\n",
        "formatter.set_scientific(False)\n",
        "\n",
        "# Lista de variables para los box plots\n",
        "variables = ['Road_55dB', 'Road_60dB', 'Railways_65dB', 'Industry_65dB']\n",
        "\n",
        "# Crear un box plot para cada variable\n",
        "for i, var in enumerate(variables):\n",
        "    sns.boxplot(data=data1[var], ax=axes[i], orient='h')  # Cambiar la orientación a horizontal\n",
        "    axes[i].set_title(f'Boxplot de {var}')\n",
        "    axes[i].xaxis.set_major_formatter(formatter)  # Aplicar el formatter a los ejes x\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "PWHUrrnKtieY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import zscore function\n",
        "from scipy.stats import zscore\n",
        "import numpy as np\n",
        "\n",
        "# Calculate z-score for each data point and compute its absolute value\n",
        "z_scores = zscore(data1['Road_55dB'])\n",
        "abs_z_scores = np.abs(z_scores)\n",
        "\n",
        "# Select the outliers using a threshold of 3\n",
        "outliers = data1[abs_z_scores > 3]\n",
        "outliers.head()"
      ],
      "metadata": {
        "id": "cvgXXdYjtf8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of outliers: {len(outliers)}')"
      ],
      "metadata": {
        "id": "P-zinBdytWrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import zscore function\n",
        "from scipy.stats import zscore\n",
        "import numpy as np\n",
        "\n",
        "# Calculate z-score for each data point and compute its absolute value\n",
        "z_scores1 = zscore(data1['Road_60dB'])\n",
        "abs_z_scores1 = np.abs(z_scores1)\n",
        "\n",
        "# Select the outliers using a threshold of 3\n",
        "outliers1 = data1[abs_z_scores1 > 3]\n",
        "outliers1.head()"
      ],
      "metadata": {
        "id": "lBOnlooRtWe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of outliers: {len(outliers1)}')"
      ],
      "metadata": {
        "id": "AoDia8z7tWc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import zscore function\n",
        "from scipy.stats import zscore\n",
        "import numpy as np\n",
        "\n",
        "# Calculate z-score for each data point and compute its absolute value\n",
        "z_scores2 = zscore(data1['Railways_65dB'])\n",
        "abs_z_scores2 = np.abs(z_scores2)\n",
        "\n",
        "# Select the outliers using a threshold of 3\n",
        "outliers2 = data1[abs_z_scores2 > 3]\n",
        "outliers2.head()"
      ],
      "metadata": {
        "id": "tBFWtMVKtWaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of outliers: {len(outliers2)}')"
      ],
      "metadata": {
        "id": "luKM3wl3tWXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import zscore function\n",
        "from scipy.stats import zscore\n",
        "import numpy as np\n",
        "\n",
        "# Calculate z-score for each data point and compute its absolute value\n",
        "z_scores3 = zscore(data1['Industry_65dB'])\n",
        "abs_z_scores3 = np.abs(z_scores3)\n",
        "\n",
        "# Select the outliers using a threshold of 3\n",
        "outliers3 = data1[abs_z_scores3 > 3]\n",
        "outliers3.head()"
      ],
      "metadata": {
        "id": "Jl79XuNjtWU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of outliers: {len(outliers3)}')"
      ],
      "metadata": {
        "id": "jfg2_wNKtu15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyod"
      ],
      "metadata": {
        "id": "_FX7sRNUtuzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import MAD estimator\n",
        "from pyod.models.mad import MAD\n",
        "\n",
        "# Set threshold to 3.5\n",
        "mad = MAD(threshold = 3.5)\n",
        "\n",
        "# Convert the 'total' column into a 2D numpy array\n",
        "total_reshaped =data1['Road_55dB'].values.reshape(-1, 1)\n",
        "\n",
        "# Generate inline and outlier labels\n",
        "labels = mad.fit(total_reshaped).labels_\n",
        "labels\n",
        "# Obtain number of outliers\n",
        "a= print(f'Number of outliers: {labels.sum()}')\n",
        "outliers5 = data1[labels == 1]\n",
        "labels,a,outliers5"
      ],
      "metadata": {
        "id": "OckWt8jPtuws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import MAD estimator\n",
        "from pyod.models.mad import MAD\n",
        "\n",
        "# Set threshold to 3.5\n",
        "mad1 = MAD(threshold = 3.5)\n",
        "\n",
        "# Convert the 'total' column into a 2D numpy array\n",
        "total_reshaped1 =data1['Road_60dB'].values.reshape(-1, 1)\n",
        "\n",
        "# Generate inline and outlier labels\n",
        "labels1 = mad1.fit(total_reshaped1).labels_\n",
        "labels1\n",
        "# Obtain number of outliers\n",
        "a1= print(f'Number of outliers: {labels1.sum()}')\n",
        "outliers51 = data1[labels1 == 1]\n",
        "labels1,a1,outliers51"
      ],
      "metadata": {
        "id": "SC-UPTPgtuuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import MAD estimator\n",
        "from pyod.models.mad import MAD\n",
        "\n",
        "# Set threshold to 3.5\n",
        "mad2 = MAD(threshold = 3.5)\n",
        "\n",
        "# Convert the 'total' column into a 2D numpy array\n",
        "total_reshaped2 =data1['Railways_65dB'].values.reshape(-1, 1)\n",
        "\n",
        "# Generate inline and outlier labels\n",
        "labels2 = mad2.fit(total_reshaped2).labels_\n",
        "labels2\n",
        "# Obtain number of outliers\n",
        "a2= print(f'Number of outliers: {labels2.sum()}')\n",
        "outliers52 = data1[labels2 == 1]\n",
        "labels2,a2,outliers52"
      ],
      "metadata": {
        "id": "HghNL_Ymturz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import MAD estimator\n",
        "from pyod.models.mad import MAD\n",
        "\n",
        "# Set threshold to 3.5\n",
        "mad3 = MAD(threshold = 3.5)\n",
        "\n",
        "# Convert the 'total' column into a 2D numpy array\n",
        "total_reshaped3 =data1['Industry_65dB'].values.reshape(-1, 1)\n",
        "\n",
        "# Generate inline and outlier labels\n",
        "labels3 = mad3.fit(total_reshaped3).labels_\n",
        "labels3\n",
        "# Obtain number of outliers\n",
        "a3= print(f'Number of outliers: {labels3.sum()}')\n",
        "outliers53 = data1[labels3 == 1]\n",
        "labels3,a3,outliers53"
      ],
      "metadata": {
        "id": "eBb-R1C9tupM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the percentiles\n",
        "seventy_fifth = data1['Railways_65dB'].quantile(0.75)\n",
        "twenty_fifth = data1['Railways_65dB'].quantile(0.25)\n",
        "\n",
        "# Obtain IQR\n",
        "iqr = seventy_fifth - twenty_fifth\n",
        "\n",
        "# Upper and lower thresholds\n",
        "upper = seventy_fifth + (1.5 * iqr)\n",
        "lower = twenty_fifth - (1.5 * iqr)\n",
        "\n",
        "# Subset the dataset\n",
        "outliers = data1[(data1['Industry_65dB'] < lower) | (data1['Industry_65dB'] > upper)]\n",
        "outliers.head()"
      ],
      "metadata": {
        "id": "dIgnilHotumr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Seleccionamos solo las tres columnas de interés\n",
        "df_selected = data1[['Road_55dB', 'Road_60dB', 'Railways_65dB', 'Industry_65dB']]\n",
        "from scipy.spatial import distance\n",
        "# Calculamos la matriz de covarianza de las variables\n",
        "cov_matrix = np.cov(df_selected, rowvar=False)\n",
        "\n",
        "# Calculamos la inversa de la matriz de covarianza\n",
        "cov_inv = np.linalg.inv(cov_matrix)\n",
        "\n",
        "# Calculamos la distancia de Mahalanobis para cada fila en el DataFrame\n",
        "dist_mahalanobis = []\n",
        "for row in df_selected.values:\n",
        "    dist = distance.mahalanobis(row, df_selected.mean(), cov_inv)\n",
        "    dist_mahalanobis.append(dist)\n",
        "\n",
        "# Agregamos la distancia de Mahalanobis como una nueva columna en el DataFrame\n",
        "data1['mahalanobis_distance'] = dist_mahalanobis\n",
        "\n",
        "# Mostramos el DataFrame con la distancia de Mahalanobis\n",
        "print(data1)"
      ],
      "metadata": {
        "id": "MW1RpL-wtukw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenamos el DataFrame por la columna de distancia de Mahalanobis en orden descendente\n",
        "df_sorted = data1.sort_values(by='mahalanobis_distance', ascending=False)\n",
        "\n",
        "# Seleccionamos los primeros tres registros con las distancias más grandes\n",
        "df_sorted.head(10)"
      ],
      "metadata": {
        "id": "h2MD4NY2tuh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "# Calculamos el LOF para las tres variables\n",
        "lof = LocalOutlierFactor()\n",
        "lof.fit_predict(df_selected)\n",
        "\n",
        "# Obtenemos los scores LOF para cada punto\n",
        "scores_lof = -lof.negative_outlier_factor_\n",
        "\n",
        "# Agregamos los scores LOF como una nueva columna en el DataFrame\n",
        "data1['lof_score'] = scores_lof\n",
        "\n",
        "# Mostramos el DataFrame con los scores LOF\n",
        "print(data1)"
      ],
      "metadata": {
        "id": "ZiCH5IsttufN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenamos el DataFrame por la columna 'lof_score' en orden descendente\n",
        "df_sorted = data1.sort_values(by='lof_score', ascending=False)\n",
        "\n",
        "# Seleccionamos los primeros tres registros con los scores LOF más grandes\n",
        "primeros_tres_lof = df_sorted.head(10)\n",
        "primeros_tres_lof"
      ],
      "metadata": {
        "id": "EsZ655s2tudI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Definimos la cantidad de árboles\n",
        "n_arboles = 100\n",
        "\n",
        "# Inicializamos y ajustamos el modelo Isolation Forest con la cantidad de árboles especificada\n",
        "isolation_forest = IsolationForest(n_estimators=n_arboles, random_state=42)\n",
        "puntajes_anomalia = isolation_forest.fit(df_selected)\n",
        "\n",
        "# Obtenemos los puntajes de anomalía para cada muestra\n",
        "puntajes_anomalia = isolation_forest.score_samples(df_selected)\n",
        "\n",
        "# Convertimos los puntajes de anomalía a valores positivos\n",
        "puntajes_anomalia = -puntajes_anomalia\n",
        "\n",
        "# Obtenemos las etiquetas de anomalía (inlier/outlier) para cada punto\n",
        "#etiquetas_anomalia = isolation_forest.predict(df_selected)\n",
        "\n",
        "# Agregamos las etiquetas de anomalía como una nueva columna en el DataFrame\n",
        "data1['puntajes_anomalia'] = puntajes_anomalia"
      ],
      "metadata": {
        "id": "a1sWuFnntuaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenamos el DataFrame por los puntajes de anomalía en orden descendente\n",
        "df_sorted = data1.sort_values(by='puntajes_anomalia', ascending=False)\n",
        "\n",
        "# Seleccionamos los primeros tres registros con los puntajes de anomalía más altos\n",
        "primeros_tres_anomalies = df_sorted.head(10)\n",
        "print(primeros_tres_anomalies)"
      ],
      "metadata": {
        "id": "uKNB2jWftuWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columnas_deseadas = ['Road_55dB', 'Road_60dB', 'Railways_65dB', 'Industry_65dB']\n",
        "\n",
        "# Hacer una copia de las columnas seleccionadas\n",
        "data2 = data1[columnas_deseadas].copy()"
      ],
      "metadata": {
        "id": "E3IgBUiituTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import ScalarFormatter\n",
        "\n",
        "# Supongamos que 'data1' es tu DataFrame y 'Road_55dB' es una columna en él\n",
        "g = sns.boxplot(data=data1, x='Industry_65dB')\n",
        "g.set_title('Boxplot de Industry_65dB')\n",
        "g.set_xlabel('Ruido')\n",
        "\n",
        "# Crear un formateador sin notación científica\n",
        "formatter = ScalarFormatter(useOffset=False)\n",
        "formatter.set_scientific(False)\n",
        "\n",
        "# Aplicar el formateador al eje x\n",
        "g.xaxis.set_major_formatter(formatter)\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YjFy2YqYuBc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data2 = data2[labels == 0]\n"
      ],
      "metadata": {
        "id": "yl7nTDj2uBXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2.describe()"
      ],
      "metadata": {
        "id": "oxmLka4VuBTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a histogram using Seaborn\n",
        "g = sns.histplot(data=data2, x='Industry_65dB', kde=True)\n",
        "# Add labels\n",
        "g.set_xlabel('Ruido')\n",
        "g.set_title('Despues')"
      ],
      "metadata": {
        "id": "GvnqQHTtuBP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a histogram with density plot using Seaborn\n",
        "g = sns.histplot(data=data1, x='Industry_65dB', kde=True)\n",
        "\n",
        "# Add labels\n",
        "g.set_xlabel('Ruido')\n",
        "\n",
        "# Add title\n",
        "g.set_title('Antes')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "shc-wIDsuBKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a box plot\n",
        "g = sns.boxplot(data = data2, x = 'Industry_65dB')\n",
        "\n",
        "# Add a title and change xlabel\n",
        "g.set_title('Despues')\n",
        "g.set_xlabel('Ruido')"
      ],
      "metadata": {
        "id": "o9-en6TguBIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a box plot\n",
        "g = sns.boxplot(data = data1, x = 'Industry_65dB')\n",
        "\n",
        "# Add a title and change xlabel\n",
        "g.set_title('Antes')\n",
        "g.set_xlabel('Ruido')"
      ],
      "metadata": {
        "id": "WkM1GQE_uBEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columnas_deseadas = ['Road_55dB', 'Road_60dB', 'Railways_65dB', 'Industry_65dB']\n",
        "# Calculate the median\n",
        "median_value = data1['Industry_65dB'].median()\n",
        "\n",
        "# Impute outliers with the median\n",
        "data3 = data1[columnas_deseadas].copy()\n",
        "data3.loc[outliers51.index, 'Industry_65dB'] = median_value"
      ],
      "metadata": {
        "id": "szFHeeNUuBCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a histogram with density plot using Seaborn\n",
        "g = sns.histplot(data=data3, x='Industry_65dB', kde=True)\n",
        "\n",
        "# Add labels\n",
        "g.set_xlabel('Ruido')\n",
        "\n",
        "# Add title\n",
        "g.set_title('Despues')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IEK6gYZIuN4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a box plot\n",
        "g = sns.boxplot(data = data3, x = 'Industry_65dB')\n",
        "\n",
        "# Add a title and change xlabel\n",
        "g.set_title('Despues')\n",
        "g.set_xlabel('Ruido')"
      ],
      "metadata": {
        "id": "uzjME-bruN0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats.mstats import winsorize\n",
        "data4_winsorized = data1[columnas_deseadas].copy()\n",
        "\n",
        "data4_winsorized['Industry_65dB'] = winsorize(data4_winsorized['Industry_65dB'],\\\n",
        "  limits = [0.1, 0.1], inplace = True)"
      ],
      "metadata": {
        "id": "LjbkG_8cuNx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a box plot\n",
        "g = sns.boxplot(data = data4_winsorized, x = 'Industry_65dB')\n",
        "\n",
        "# Add a title and change xlabel\n",
        "g.set_title('Despues')\n",
        "g.set_xlabel('Ruido')"
      ],
      "metadata": {
        "id": "tSizHPXquNvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Punto 2"
      ],
      "metadata": {
        "id": "QhRZCy3hugFM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Cargue y explore el dataset explicando en qué consiste y las características que posee el mismo."
      ],
      "metadata": {
        "id": "2BFJS_ZfujIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wP9VdAbcuNsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librerías\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_context('talk')\n",
        "import sqlite3\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "import missingno as msno"
      ],
      "metadata": {
        "id": "zwhhfZgBuNp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ruta = '/content/drive/Othercomputers/Mi portátil/SEMESTRE 9/Introduccion mineria de datos/Parcial/auto-mpg.data-original.txt'\n"
      ],
      "metadata": {
        "id": "vOZ5b3iQuNm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year', 'Origin', 'Car Name']\n",
        "data = pd.read_csv(ruta, delim_whitespace=True, names=column_names, na_values='NA')"
      ],
      "metadata": {
        "id": "hqcKAqBnuNjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "Wl-L9vx1uNhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Cylinders'] = data['Cylinders'].astype('int')\n",
        "data['Model Year'] = data['Model Year'].astype('int')\n",
        "data['Origin'] = data['Origin'].astype('int')\n",
        "data['Car Name'] = data['Car Name'].astype('category')"
      ],
      "metadata": {
        "id": "eHLrIT6IuNeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "V6RmNaswuNbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.size"
      ],
      "metadata": {
        "id": "EXvqYAQJuNYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "w4gY_uN8uNVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_data = data.isnull().sum()\n",
        "print(\"Cantidad de datos faltantes por variable:\")\n",
        "print(missing_data)\n",
        "\n",
        "##Hago el conteo de columnas cuya fila sea igual a cero\n",
        "cols = data[data == 0].count(axis=0)\n",
        "##Reviso cuántas columnas tienen filas con valores en cero\n",
        "a = cols[cols > 0]\n",
        "\n",
        "print(\"Cantidad de datos en cero por variable:\")\n",
        "print(a)"
      ],
      "metadata": {
        "id": "pvaqxXYGuNSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how many total missing values do we have?\n",
        "total_cells = np.product(data.shape)\n",
        "total_missing = missing_data.sum()\n",
        "\n",
        "# percent of data that is missing\n",
        "(total_missing/total_cells) * 100"
      ],
      "metadata": {
        "id": "8RI6ZMhNuNPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import missingno as msno\n",
        "msno.bar(data,figsize=(12, 6), sort=\"ascending\",fontsize=12, color='steelblue')\n",
        "\n",
        "#color='steelblue')\n",
        "#color=\"dodgerblue\")\n",
        "#color=\"tab:green\")"
      ],
      "metadata": {
        "id": "Z19nH8mBuNLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b. Realice un breve análisis exploratorio para identificar la distribución de las variables usadas en la base de datos ¿será que existe relación entre las variables?"
      ],
      "metadata": {
        "id": "DvCJVhQ2u32J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Dibujar histogramas en orientación horizontal, uno debajo del otro\n",
        "col_num = ['MPG', 'Displacement', 'Horsepower','Weight','Acceleration']\n",
        "# No se coloca cylinders ya que parece ser una variable categórica\n",
        "\n",
        "fig, ax = plt.subplots(nrows=5, ncols=1, figsize=(10, 20)) # Cambio aquí para acomodar los gráficos verticalmente\n",
        "fig.subplots_adjust(hspace=0.5) # Ajustar el espacio entre gráficos\n",
        "\n",
        "for i, col in enumerate(col_num):\n",
        "    if col == 'MPG':\n",
        "        nbins = 10\n",
        "    else:\n",
        "        nbins = 50\n",
        "    sns.histplot(x=col, data=data, ax=ax[i], bins=nbins, kde=True) # Mantener x=col para orientación horizontal\n",
        "    ax[i].set_title(col)\n"
      ],
      "metadata": {
        "id": "Vef3aBhkuNIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Dibujar histogramas\n",
        "col_num = ['Cylinders', 'Model Year', 'Origin', 'Car Name']\n",
        "\n",
        "# Asumiendo que ya tienes tus datos cargados en una variable llamada 'data'\n",
        "\n",
        "fig, ax = plt.subplots(nrows=4, ncols=1, figsize=(8, 20))  # Cambiado a 4 filas y 1 columna\n",
        "fig.subplots_adjust(hspace=0.5)  # Ajuste de espacio vertical\n",
        "\n",
        "for i, col in enumerate(col_num):\n",
        "    if col == 'Cylinders':\n",
        "        nbins = 10\n",
        "    else:\n",
        "        nbins = 50\n",
        "    sns.histplot(x=col, data=data, ax=ax[i], bins=nbins)\n",
        "    ax[i].set_title(col)\n",
        "    ax[i].set_xlabel('')  # Quitamos la etiqueta x para mejorar la visualización\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "MTUR5FSFuNFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cantidad_registros_unicos = data['Car Name'].nunique()\n",
        "\n",
        "print(\"Cantidad de registros únicos:\", cantidad_registros_unicos)\n"
      ],
      "metadata": {
        "id": "Jb2QTMNDuNCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "import pandas as pd\n",
        "\n",
        "# Suponiendo que 'data' es tu DataFrame\n",
        "data11 = data[['MPG', 'Displacement', 'Horsepower', 'Weight', 'Acceleration']].copy()\n",
        "\n",
        "# Eliminar filas con valores NaN\n",
        "data11 = data11.dropna()\n",
        "\n",
        "# Iterar sobre las columnas y realizar la prueba de Shapiro-Wilk\n",
        "alpha = 0.05\n",
        "for column in data11.columns:\n",
        "    statistic, p_value = stats.shapiro(data11[column])\n",
        "    print(f\"Variable: {column}\")\n",
        "    print(\"Estadístico de prueba:\", statistic)\n",
        "    print(\"Valor p:\", p_value)\n",
        "\n",
        "    # Interpretar el resultado\n",
        "    if p_value > alpha:\n",
        "        print(\"No se rechaza la hipótesis nula (los datos provienen de una distribución normal)\")\n",
        "    else:\n",
        "        print(\"Se rechaza la hipótesis nula (los datos no provienen de una distribución normal)\")\n"
      ],
      "metadata": {
        "id": "MaKKwgoouA_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia\n",
        "data1 = data.copy()\n",
        "\n",
        "# Eliminar todas las filas que contienen al menos un valor faltante\n",
        "data1.dropna(inplace=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q5-JOMSzuyC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sin datos faltantes\n",
        "data1.describe()"
      ],
      "metadata": {
        "id": "aL0LDlA9ux9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Supongamos que 'data' es tu DataFrame de Pandas que contiene todas las variables\n",
        "# que deseas visualizar en el pairplot\n",
        "\n",
        "# Por ejemplo, si deseas visualizar las variables 'MPG', 'Displacement', 'Horsepower',\n",
        "# 'Weight' y 'Acceleration', puedes seleccionarlas así:\n",
        "variables = ['MPG', 'Displacement', 'Horsepower', 'Weight', 'Acceleration','Cylinders', 'Model Year', 'Origin', 'Car Name']\n",
        "data_selected = data[variables]\n",
        "\n",
        "# Ahora puedes usar sns.pairplot() para visualizar todas las relaciones entre estas variables\n",
        "sns.pairplot(data_selected, diag_kind=\"hist\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "f1cihwBBux6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar las variables para el heatmap\n",
        "variables_heatmap = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year', 'Origin']\n",
        "\n",
        "# Calcular la matriz de correlación\n",
        "correlation_matrix = data[variables_heatmap].corr()\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
        "\n",
        "# Ajustar los límites de los ejes X e Y\n",
        "plt.xlim(0, correlation_matrix.shape[1])\n",
        "plt.ylim(0, correlation_matrix.shape[0])\n",
        "\n",
        "plt.title('Heatmap de correlación de variables en la base de datos Auto MPG')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "x-kbkMcSux3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_data = data.isnull().sum()\n",
        "print(\"Cantidad de datos faltantes por variable:\")\n",
        "print(missing_data)\n",
        "\n",
        "##Hago el conteo de columnas cuya fila sea igual a cero\n",
        "cols = data[data == 0].count(axis=0)\n",
        "##Reviso cuántas columnas tienen filas con valores en cero\n",
        "a = cols[cols > 0]\n",
        "\n",
        "print(\"Cantidad de datos en cero por variable:\")\n",
        "print(a)"
      ],
      "metadata": {
        "id": "dZavPK5-ux1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how many total missing values do we have?\n",
        "total_cells = np.product(data.shape)\n",
        "total_missing = missing_data.sum()\n",
        "\n",
        "# percent of data that is missing\n",
        "(total_missing/total_cells) * 100"
      ],
      "metadata": {
        "id": "58_5F5bnuxzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import missingno as msno\n",
        "\n",
        "# Verificar que ya no hay datos faltantes en la nueva base\n",
        "missing_data_complete_cases = data.isnull().sum()\n",
        "missing_data_complete_cases\n",
        "#\n",
        "\n"
      ],
      "metadata": {
        "id": "PO7P9nujuxuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "\n",
        "ruta = \"/content/drive/Othercomputers/Mi portátil/SEMESTRE 9/Introduccion mineria de datos/Parcial/auto-mpg.data-original.txt\"\n",
        "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year', 'Origin', 'Car Name']\n",
        "data = pd.read_csv(ruta, delim_whitespace=True, names=column_names, na_values='NA')\n",
        "\n",
        "missing_data = data.isnull().sum()\n",
        "\n",
        "missing_proportion = missing_data / len(data)*100\n",
        "\n",
        "print(\"Cantidad de datos faltantes por variable:\")\n",
        "print(missing_data)\n",
        "print(\"\\nProporción de datos faltantes por variable:\")\n",
        "print(missing_proportion)\n",
        "\n",
        "msno.bar(data,figsize=(10, 5), fontsize=12, color='steelblue')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3n0sf5tquxsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_data_total = missing_data.sum() / len(data)\n",
        "print(\"Porcentaje total de datos faltantes en el conjunto de datos:\", missing_data_total,\"(\",round(missing_data_total*100,2),\"%)\")"
      ],
      "metadata": {
        "id": "SjscEa0_uxqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TigQ86ixuxnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Listar registros faltantes\n",
        "missing_data_rows = data[data['MPG'].isnull() | data['Horsepower'].isnull()]\n",
        "\n",
        "print(missing_data_rows)\n"
      ],
      "metadata": {
        "id": "jo8_wsCUuxlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# E. Aplique las técnicas de tratamiento de datos faltantes vistas en clase."
      ],
      "metadata": {
        "id": "dgbdjGnyvW-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Copia\n",
        "data_complete_cases = data.copy()\n",
        "\n",
        "# Eliminar todas las filas que contienen al menos un valor faltante\n",
        "data_complete_cases.dropna(inplace=True)\n",
        "\n",
        "# Verificar que ya no hay datos faltantes en la nueva base\n",
        "missing_data_complete_cases = data_complete_cases.isnull().sum()\n",
        "\n",
        "#Validamos como quedan los datos\n",
        "msno.bar(data_complete_cases,figsize=(12, 6), fontsize=12, color='steelblue')\n",
        "\n",
        "data_complete_cases.describe()\n"
      ],
      "metadata": {
        "id": "zYsep44tuxir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Copia\n",
        "data_most_frequent = data.copy()\n",
        "\n",
        "# Crear un imputador con la estrategia 'most_frequent'\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Imputar los valores faltantes en el DataFrame\n",
        "data_most_frequent.iloc[:,:] = imputer.fit_transform(data_most_frequent)\n",
        "\n",
        "missing_data_most_frequent = data_most_frequent.isnull().sum()\n",
        "\n",
        "\n",
        "#Validamos como quedan los datos\n",
        "msno.bar(data_most_frequent,figsize=(12, 6), fontsize=12, color='steelblue')\n",
        "\n",
        "data_most_frequent.describe()"
      ],
      "metadata": {
        "id": "KTytb8PNvbzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el valor medio de las variables presentes\n",
        "mean_MPG = data['MPG'].mean()\n",
        "mean_Horsepower = data['Horsepower'].mean()\n",
        "\n",
        "# Copiar el DataFrame original\n",
        "data_mean_imputed = data.copy()\n",
        "\n",
        "# Imputar los valores faltantes por la media\n",
        "data_mean_imputed['MPG'].fillna(mean_MPG, inplace=True)\n",
        "data_mean_imputed['Horsepower'].fillna(mean_Horsepower, inplace=True)\n",
        "\n",
        "\n",
        "#Validamos como quedan los datos\n",
        "msno.bar(data_mean_imputed,figsize=(12, 6), fontsize=12, color='steelblue')\n",
        "\n",
        "data_mean_imputed.describe()"
      ],
      "metadata": {
        "id": "gKEArZy_vbwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia\n",
        "data_cold_deck_imputed = data.copy()\n",
        "\n",
        "# Imputar los valores faltantes por la mediana para ambas variables\n",
        "data_cold_deck_imputed['MPG'].fillna(data_cold_deck_imputed['MPG'].median(), inplace=True)\n",
        "data_cold_deck_imputed['Horsepower'].fillna(data_cold_deck_imputed['Horsepower'].median(), inplace=True)\n",
        "\n",
        "# Verificar que ya no hay datos faltantes en la nueva base\n",
        "missing_data_cold_deck_imputed = data_cold_deck_imputed.isnull().sum()\n",
        "\n",
        "\n",
        "data_cold_deck_imputed.describe()"
      ],
      "metadata": {
        "id": "w9CxCmXLvbq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia\n",
        "data_hot_deck_imputed = data.copy()\n",
        "\n",
        "# Iterar sobre cada fila del DataFrame\n",
        "for i, row in data_hot_deck_imputed.iterrows():\n",
        "    # Verificar si la fila actual tiene datos faltantes en MPG o Horsepower\n",
        "    if pd.isnull(row['MPG']) or pd.isnull(row['Horsepower']):\n",
        "        # Calcular la distancia euclidiana con respecto a las otras filas para las variables MPG y Horsepower\n",
        "        distances = []\n",
        "        for j, other_row in data_hot_deck_imputed.iterrows():\n",
        "            if i != j and not pd.isnull(other_row['MPG']) and not pd.isnull(other_row['Horsepower']):\n",
        "                distance = ((row['MPG'] - other_row['MPG'])**2 + (row['Horsepower'] - other_row['Horsepower'])**2)**0.5\n",
        "                distances.append((j, distance))\n",
        "        # Ordenar las distancias de menor a mayor\n",
        "        distances.sort(key=lambda x: x[1])\n",
        "        # Obtener el índice del registro maas cercano con valores no faltantes\n",
        "        closest_index = distances[0][0]\n",
        "        # Imputar los valores faltantes con los valores del registro más cercano\n",
        "        data_hot_deck_imputed.at[i, 'MPG'] = data_hot_deck_imputed.at[closest_index, 'MPG']\n",
        "        data_hot_deck_imputed.at[i, 'Horsepower'] = data_hot_deck_imputed.at[closest_index, 'Horsepower']\n",
        "\n",
        "#Validamos como quedan los datos\n",
        "msno.bar(data_hot_deck_imputed,figsize=(12, 6), fontsize=12, color='steelblue')\n",
        "\n",
        "data_hot_deck_imputed.describe()\n"
      ],
      "metadata": {
        "id": "ngkafwfFvbn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Copia\n",
        "data_regression_imputed = data.copy()\n",
        "\n",
        "#  modelo de regresión lineal\n",
        "model = LinearRegression()\n",
        "\n",
        "# Iterar sobre cada fila de la base\n",
        "for i, row in data_regression_imputed.iterrows():\n",
        "    # Verificar si la fila actual tiene datos faltantes en MPG o Horsepower\n",
        "    if pd.isnull(row['MPG']) or pd.isnull(row['Horsepower']):\n",
        "        # Separar los datos en dos grupos: con valores no faltantes y con valores faltantes\n",
        "        data_train = data_regression_imputed.dropna()\n",
        "        data_test = data_regression_imputed.loc[i].to_frame().T\n",
        "        # modelo\n",
        "        model.fit(data_train[['Cylinders', 'Displacement', 'Weight', 'Acceleration', 'Model Year']], data_train['MPG'])\n",
        "        # Predecir el valor faltante de MPG\n",
        "        mpg_predicted = model.predict(data_test[['Cylinders', 'Displacement', 'Weight', 'Acceleration', 'Model Year']])\n",
        "        # Imputar el valor faltante de MPG\n",
        "        data_regression_imputed.at[i, 'MPG'] = mpg_predicted[0]\n",
        "\n",
        "        # modelo\n",
        "        model.fit(data_train[['Cylinders', 'Displacement', 'Weight', 'Acceleration', 'Model Year']], data_train['Horsepower'])\n",
        "        # Predecir el valor faltante de Horsepower\n",
        "        horsepower_predicted = model.predict(data_test[['Cylinders', 'Displacement', 'Weight', 'Acceleration', 'Model Year']])\n",
        "        # Imputar el valor faltante de Horsepower\n",
        "        data_regression_imputed.at[i, 'Horsepower'] = horsepower_predicted[0]\n",
        "\n",
        "\n",
        "#Validamos como quedan los datos\n",
        "msno.bar(data_regression_imputed,figsize=(12, 6), fontsize=12, color='steelblue')\n",
        "\n",
        "data_regression_imputed.describe()\n"
      ],
      "metadata": {
        "id": "NvFQLZ1bvblL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "\n",
        "# Copia\n",
        "data_mice = data.copy()\n",
        "\n",
        "# Seleccionar las variables numéricas a imputar\n",
        "numeric_vars = ['MPG', 'Horsepower']\n",
        "\n",
        "# Crear un imputador MICE con el estimador BayesianRidge\n",
        "mice_imputer = IterativeImputer(random_state=0, estimator=BayesianRidge())\n",
        "\n",
        "# Imputar los valores faltantes en las variables seleccionadas\n",
        "data_mice[numeric_vars] = mice_imputer.fit_transform(data_mice[numeric_vars])\n",
        "\n",
        "\n",
        "#Validamos como quedan los datos\n",
        "msno.bar(data_mice,figsize=(12, 6), fontsize=12, color='steelblue')\n",
        "\n",
        "data_mice.describe()"
      ],
      "metadata": {
        "id": "Vw7yDcEGvbfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# Copiar el DataFrame original\n",
        "data_knn = data.copy()\n",
        "\n",
        "# Seleccionar las variables numéricas a imputar\n",
        "numeric_vars = ['MPG', 'Horsepower']\n",
        "\n",
        "# Crear un imputador KNN con 5 vecinos y pesos uniformes\n",
        "knn_imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
        "\n",
        "# Imputar los valores faltantes en las variables seleccionadas\n",
        "data_knn[numeric_vars] = knn_imputer.fit_transform(data_knn[numeric_vars])\n",
        "\n",
        "\n",
        "#Validamos como quedan los datos\n",
        "msno.bar(data_knn,figsize=(12, 6), fontsize=12, color='steelblue')\n",
        "\n",
        "data_knn.describe()"
      ],
      "metadata": {
        "id": "efIcpn4Pvbcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# F. Analice gráfica y analíticamente la variación en la distribución de los datos al aplicar las técnicas de imputación de datos. ¿Qué técnica afecta menos la distribución original?"
      ],
      "metadata": {
        "id": "FNlTOiajvpvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Valor imputado para MPG con el método 'Más frecuente':\")\n",
        "print(data_most_frequent['MPG'].iloc[[10, 11, 12, 13, 14, 17, 39, 367]])\n",
        "\n",
        "print(\"Valor imputado para MPG con el método 'Sustitución por medias':\")\n",
        "print(data_mean_imputed['MPG'].iloc[[10, 11, 12, 13, 14, 17, 39, 367]])\n",
        "\n",
        "print(\"Valor imputado para MPG con el método 'Cold Deck':\")\n",
        "print(data_cold_deck_imputed['MPG'].iloc[[10, 11, 12, 13, 14, 17, 39, 367]])\n",
        "\n",
        "print(\"Valor imputado para MPG con el método 'Hot Deck':\")\n",
        "print(data_hot_deck_imputed['MPG'].iloc[[10, 11, 12, 13, 14, 17, 39, 367]])\n",
        "\n",
        "print(\"Valor imputado para MPG con el método 'Regresión':\")\n",
        "print(data_regression_imputed['MPG'].iloc[[10, 11, 12, 13, 14, 17, 39, 367]])\n",
        "\n",
        "print(\"Valor imputado para MPG con el método 'MICE':\")\n",
        "print(data_mice['MPG'].iloc[[10, 11, 12, 13, 14, 17, 39, 367]])\n",
        "\n",
        "print(\"Valor imputado para MPG con el método 'K-Nearest Neighbor Imputation':\")\n",
        "print(data_knn['MPG'].iloc[[10, 11, 12, 13, 14, 17, 39, 367]])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NgQ1WxldvbZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Valor imputado para Horsepower con el método 'Más frecuente':\")\n",
        "print(data_most_frequent['Horsepower'].iloc[[38, 133, 337, 343, 361, 382]])\n",
        "\n",
        "print(\"Valor imputado para Horsepower con el método 'Sustitución por medias':\")\n",
        "print(data_mean_imputed['Horsepower'].iloc[[38, 133, 337, 343, 361, 382]])\n",
        "\n",
        "print(\"Valor imputado para Horsepower con el método 'Cold Deck':\")\n",
        "print(data_cold_deck_imputed['Horsepower'].iloc[[38, 133, 337, 343, 361, 382]])\n",
        "\n",
        "print(\"Valor imputado para Horsepower con el método 'Hot Deck':\")\n",
        "print(data_hot_deck_imputed['Horsepower'].iloc[[38, 133, 337, 343, 361, 382]])\n",
        "\n",
        "print(\"Valor imputado para Horsepower con el método 'Regresión':\")\n",
        "print(data_regression_imputed['Horsepower'].iloc[[38, 133, 337, 343, 361, 382]])\n",
        "\n",
        "print(\"Valor imputado para Horsepower con el método 'MICE':\")\n",
        "print(data_mice['Horsepower'].iloc[[38, 133, 337, 343, 361, 382]])\n",
        "\n",
        "print(\"Valor imputado para Horsepower con el método 'K-Nearest Neighbor Imputation':\")\n",
        "print(data_knn['Horsepower'].iloc[[38, 133, 337, 343, 361, 382]])\n"
      ],
      "metadata": {
        "id": "0auDXjjxvbUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MPG\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "\n",
        "sns.histplot(data['MPG'], ax=axes[0], kde=True)\n",
        "axes[0].set_title('Distribución de MPG (Original)')\n",
        "\n",
        "\n",
        "sns.histplot(data_complete_cases['MPG'], ax=axes[1], kde=True)\n",
        "axes[1].set_title('Distribución de MPG (Imputada con Elimnacion dato faltante)')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# HP\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "\n",
        "sns.histplot(data['Horsepower'], ax=axes[0], kde=True)\n",
        "axes[0].set_title('Distribución de Horsepower (Original)')\n",
        "\n",
        "\n",
        "sns.histplot(data_complete_cases['Horsepower'], ax=axes[1], kde=True)\n",
        "axes[1].set_title('Distribución de Horsepower (Imputada con Elimnacion dato faltante)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y4QflH7PvbQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MPG\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "sns.histplot(data['MPG'], ax=axes[0], kde=True)\n",
        "axes[0].set_title('Distribución de MPG (Original)')\n",
        "\n",
        "sns.histplot(data_most_frequent['MPG'], ax=axes[1], kde=True)\n",
        "axes[1].set_title('Distribución de MPG (Imputada con Elimnacion Más frecuente)')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# HP\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "\n",
        "sns.histplot(data['Horsepower'], ax=axes[0], kde=True)\n",
        "axes[0].set_title('Distribución de Horsepower (Original)')\n",
        "\n",
        "\n",
        "sns.histplot(data_most_frequent['Horsepower'], ax=axes[1], kde=True)\n",
        "axes[1].set_title('Distribución de Horsepower (Imputada con Elimnacion Más frecuente)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oRCpXBTDvbNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MPG\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "sns.histplot(data['MPG'], ax=axes[0], kde=True)\n",
        "axes[0].set_title('Distribución de MPG (Original)')\n",
        "\n",
        "sns.histplot(data_mean_imputed['MPG'], ax=axes[1], kde=True)\n",
        "axes[1].set_title('Distribución de MPG (Imputada con Sustitución medias)')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# HP\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "\n",
        "sns.histplot(data['Horsepower'], ax=axes[0], kde=True)\n",
        "axes[0].set_title('Distribución de Horsepower (Original)')\n",
        "\n",
        "\n",
        "sns.histplot(data_mean_imputed['Horsepower'], ax=axes[1], kde=True)\n",
        "axes[1].set_title('Distribución de Horsepower (Imputada con  Sustitución medias)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i32eJZGBvapG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MPG\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "sns.histplot(data['MPG'], ax=axes[0], kde=True)\n",
        "axes[0].set_title('Distribución de MPG (Original)')\n",
        "\n",
        "sns.histplot(data_cold_deck_imputed['MPG'], ax=axes[1], kde=True)\n",
        "axes[1].set_title('Distribución de MPG (Imputada con Cold Deck)')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# HP\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "\n",
        "sns.histplot(data['Horsepower'], ax=axes[0], kde=True)\n",
        "axes[0].set_title('Distribución de Horsepower (Original)')\n",
        "\n",
        "\n",
        "sns.histplot(data_cold_deck_imputed['Horsepower'], ax=axes[1], kde=True)\n",
        "axes[1].set_title('Distribución de Horsepower (Imputada con Cold Deck)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8MwAATOyuxfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MPG\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "sns.histplot(data['MPG'], ax=axes[0], kde=True)\n",
        "axes[0].set_title('Distribución de MPG (Original)')\n",
        "\n",
        "sns.histplot(data_hot_deck_imputed['MPG'], ax=axes[1], kde=True)\n",
        "axes[1].set_title('Distribución de MPG (Imputada con Hot Deck)')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "#HP\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "\n",
        "sns.histplot(data['Horsepower'], ax=axes[0], kde=True)\n",
        "axes[0].set_title('Distribución de Horsepower (Original)')\n",
        "\n",
        "\n",
        "sns.histplot(data_hot_deck_imputed['Horsepower'], ax=axes[1], kde=True)\n",
        "axes[1].set_title('Distribución de Horsepower (Imputada con Hot Deck)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xbk5pu4fuxcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "#MPG\n",
        "sns.histplot(data['MPG'], ax=axes[0], kde=True)\n",
        "axes[0].set_title('Distribución de MPG (Original)')\n",
        "\n",
        "sns.histplot(data_regression_imputed['MPG'], ax=axes[1], kde=True)\n",
        "axes[1].set_title('Distribución de MPG (Imputada con Regresión multiple)')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#horsepower\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "\n",
        "sns.histplot(data['Horsepower'], ax=axes[0], kde=True)\n",
        "axes[0].set_title('Distribución de Horsepower (Original)')\n",
        "\n",
        "\n",
        "sns.histplot(data_regression_imputed['Horsepower'], ax=axes[1], kde=True)\n",
        "axes[1].set_title('Distribución de Horsepower (Imputada con Regresión multiple)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rXa3pgYMuxW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "#MPG\n",
        "sns.histplot(data['MPG'], ax=axes[0], kde=True)\n",
        "axes[0].set_title('Distribución de MPG (Original)')\n",
        "\n",
        "sns.histplot(data_mice['MPG'], ax=axes[1], kde=True)\n",
        "axes[1].set_title('Distribución de MPG (Imputada con MICE)')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#horsepower\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "\n",
        "sns.histplot(data['Horsepower'], ax=axes[0], kde=True)\n",
        "axes[0].set_title('Distribución de Horsepower (Original)')\n",
        "\n",
        "\n",
        "sns.histplot(data_mice['Horsepower'], ax=axes[1], kde=True)\n",
        "axes[1].set_title('Distribución de Horsepower (Imputada con MICE)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bpgl7Yt3uxUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "#MPG\n",
        "sns.histplot(data['MPG'], ax=axes[0], kde=True)\n",
        "axes[0].set_title('Distribución de MPG (Original)')\n",
        "\n",
        "sns.histplot(data_knn['MPG'], ax=axes[1], kde=True)\n",
        "axes[1].set_title('Distribución de MPG (Imputada con KNN)')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#horsepower\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "\n",
        "sns.histplot(data['Horsepower'], ax=axes[0], kde=True)\n",
        "axes[0].set_title('Distribución de Horsepower (Original)')\n",
        "\n",
        "\n",
        "sns.histplot(data_knn['Horsepower'], ax=axes[1], kde=True)\n",
        "axes[1].set_title('Distribución de Horsepower (Imputada con KNN)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1Y3BTNJRuxRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pruebas shapiro para cada metodo de imputación"
      ],
      "metadata": {
        "id": "Uofz8QqzAmnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "import pandas as pd\n",
        "\n",
        "# Suponiendo que 'data' es tu DataFrame\n",
        "data11 = data_complete_cases[['MPG','Horsepower',]].copy()\n",
        "\n",
        "\n",
        "\n",
        "# Iterar sobre las columnas y realizar la prueba de Shapiro-Wilk\n",
        "alpha = 0.05\n",
        "for column in data11.columns:\n",
        "    statistic, p_value = stats.shapiro(data11[column])\n",
        "    print(f\"Variable: {column}\")\n",
        "    print(\"Estadístico de prueba:\", statistic)\n",
        "    print(\"Valor p:\", p_value)\n",
        "\n",
        "    # Interpretar el resultado\n",
        "    if p_value > alpha:\n",
        "        print(\"No se rechaza la hipótesis nula (los datos provienen de una distribución normal)\")\n",
        "    else:\n",
        "        print(\"Se rechaza la hipótesis nula (los datos no provienen de una distribución normal)\")\n"
      ],
      "metadata": {
        "id": "vois5YKAAmNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "import pandas as pd\n",
        "\n",
        "# Suponiendo que 'data' es tu DataFrame\n",
        "data11 = data_most_frequent[['MPG','Horsepower',]].copy()\n",
        "\n",
        "\n",
        "\n",
        "# Iterar sobre las columnas y realizar la prueba de Shapiro-Wilk\n",
        "alpha = 0.05\n",
        "for column in data11.columns:\n",
        "    statistic, p_value = stats.shapiro(data11[column])\n",
        "    print(f\"Variable: {column}\")\n",
        "    print(\"Estadístico de prueba:\", statistic)\n",
        "    print(\"Valor p:\", p_value)\n",
        "\n",
        "    # Interpretar el resultado\n",
        "    if p_value > alpha:\n",
        "        print(\"No se rechaza la hipótesis nula (los datos provienen de una distribución normal)\")\n",
        "    else:\n",
        "        print(\"Se rechaza la hipótesis nula (los datos no provienen de una distribución normal)\")\n"
      ],
      "metadata": {
        "id": "zSCJF0sNuxO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MPG\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "sns.histplot(data['MPG'], ax=axes[0], kde=True)\n",
        "axes[0].set_title('Distribución de MPG (Original)')\n",
        "\n",
        "sns.histplot(data_mean_imputed['MPG'], ax=axes[1], kde=True)\n",
        "axes[1].set_title('Distribución de MPG (Imputada con Sustitución medias)')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# HP\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "\n",
        "sns.histplot(data['Horsepower'], ax=axes[0], kde=True)\n",
        "axes[0].set_title('Distribución de Horsepower (Original)')\n",
        "\n",
        "\n",
        "sns.histplot(data_mean_imputed['Horsepower'], ax=axes[1], kde=True)\n",
        "axes[1].set_title('Distribución de Horsepower (Imputada con  Sustitución medias)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uaOl_vU4As5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "import pandas as pd\n",
        "\n",
        "# Suponiendo que 'data' es tu DataFrame\n",
        "data11 = data_mean_imputed[['MPG','Horsepower',]].copy()\n",
        "\n",
        "\n",
        "\n",
        "# Iterar sobre las columnas y realizar la prueba de Shapiro-Wilk\n",
        "alpha = 0.05\n",
        "for column in data11.columns:\n",
        "    statistic, p_value = stats.shapiro(data11[column])\n",
        "    print(f\"Variable: {column}\")\n",
        "    print(\"Estadístico de prueba:\", statistic)\n",
        "    print(\"Valor p:\", p_value)\n",
        "\n",
        "    # Interpretar el resultado\n",
        "    if p_value > alpha:\n",
        "        print(\"No se rechaza la hipótesis nula (los datos provienen de una distribución normal)\")\n",
        "    else:\n",
        "        print(\"Se rechaza la hipótesis nula (los datos no provienen de una distribución normal)\")\n"
      ],
      "metadata": {
        "id": "iS8WKerOAs0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "import pandas as pd\n",
        "\n",
        "# Suponiendo que 'data' es tu DataFrame\n",
        "data11 = data_cold_deck_imputed[['MPG','Horsepower',]].copy()\n",
        "\n",
        "\n",
        "\n",
        "# Iterar sobre las columnas y realizar la prueba de Shapiro-Wilk\n",
        "alpha = 0.05\n",
        "for column in data11.columns:\n",
        "    statistic, p_value = stats.shapiro(data11[column])\n",
        "    print(f\"Variable: {column}\")\n",
        "    print(\"Estadístico de prueba:\", statistic)\n",
        "    print(\"Valor p:\", p_value)\n",
        "\n",
        "    # Interpretar el resultado\n",
        "    if p_value > alpha:\n",
        "        print(\"No se rechaza la hipótesis nula (los datos provienen de una distribución normal)\")\n",
        "    else:\n",
        "        print(\"Se rechaza la hipótesis nula (los datos no provienen de una distribución normal)\")\n"
      ],
      "metadata": {
        "id": "DBA9PcRRAsxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "import pandas as pd\n",
        "\n",
        "# Suponiendo que 'data' es tu DataFrame\n",
        "data11 = data_hot_deck_imputed[['MPG','Horsepower',]].copy()\n",
        "\n",
        "\n",
        "# Iterar sobre las columnas y realizar la prueba de Shapiro-Wilk\n",
        "alpha = 0.05\n",
        "for column in data11.columns:\n",
        "    statistic, p_value = stats.shapiro(data11[column])\n",
        "    print(f\"Variable: {column}\")\n",
        "    print(\"Estadístico de prueba:\", statistic)\n",
        "    print(\"Valor p:\", p_value)\n",
        "\n",
        "    # Interpretar el resultado\n",
        "    if p_value > alpha:\n",
        "        print(\"No se rechaza la hipótesis nula (los datos provienen de una distribución normal)\")\n",
        "    else:\n",
        "        print(\"Se rechaza la hipótesis nula (los datos no provienen de una distribución normal)\")\n"
      ],
      "metadata": {
        "id": "YXn-cV_pAstA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "import pandas as pd\n",
        "\n",
        "# Suponiendo que 'data' es tu DataFrame\n",
        "data11 = data_regression_imputed[['MPG','Horsepower',]].copy()\n",
        "\n",
        "\n",
        "\n",
        "# Iterar sobre las columnas y realizar la prueba de Shapiro-Wilk\n",
        "alpha = 0.05\n",
        "for column in data11.columns:\n",
        "    statistic, p_value = stats.shapiro(data11[column])\n",
        "    print(f\"Variable: {column}\")\n",
        "    print(\"Estadístico de prueba:\", statistic)\n",
        "    print(\"Valor p:\", p_value)\n",
        "\n",
        "    # Interpretar el resultado\n",
        "    if p_value > alpha:\n",
        "        print(\"No se rechaza la hipótesis nula (los datos provienen de una distribución normal)\")\n",
        "    else:\n",
        "        print(\"Se rechaza la hipótesis nula (los datos no provienen de una distribución normal)\")\n"
      ],
      "metadata": {
        "id": "2yhX-L65AsqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "import pandas as pd\n",
        "\n",
        "# Suponiendo que 'data' es tu DataFrame\n",
        "data11 = data_mice[['MPG','Horsepower',]].copy()\n",
        "\n",
        "\n",
        "\n",
        "# Iterar sobre las columnas y realizar la prueba de Shapiro-Wilk\n",
        "alpha = 0.05\n",
        "for column in data11.columns:\n",
        "    statistic, p_value = stats.shapiro(data11[column])\n",
        "    print(f\"Variable: {column}\")\n",
        "    print(\"Estadístico de prueba:\", statistic)\n",
        "    print(\"Valor p:\", p_value)\n",
        "\n",
        "    # Interpretar el resultado\n",
        "    if p_value > alpha:\n",
        "        print(\"No se rechaza la hipótesis nula (los datos provienen de una distribución normal)\")\n",
        "    else:\n",
        "        print(\"Se rechaza la hipótesis nula (los datos no provienen de una distribución normal)\")\n"
      ],
      "metadata": {
        "id": "o9vWhA_rAsO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "import pandas as pd\n",
        "\n",
        "# Suponiendo que 'data' es tu DataFrame\n",
        "data11 = data_knn[['MPG','Horsepower',]].copy()\n",
        "\n",
        "\n",
        "\n",
        "# Iterar sobre las columnas y realizar la prueba de Shapiro-Wilk\n",
        "alpha = 0.05\n",
        "for column in data11.columns:\n",
        "    statistic, p_value = stats.shapiro(data11[column])\n",
        "    print(f\"Variable: {column}\")\n",
        "    print(\"Estadístico de prueba:\", statistic)\n",
        "    print(\"Valor p:\", p_value)\n",
        "\n",
        "    # Interpretar el resultado\n",
        "    if p_value > alpha:\n",
        "        print(\"No se rechaza la hipótesis nula (los datos provienen de una distribución normal)\")\n",
        "    else:\n",
        "        print(\"Se rechaza la hipótesis nula (los datos no provienen de una distribución normal)\")\n"
      ],
      "metadata": {
        "id": "g0u88oQxBA5S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}